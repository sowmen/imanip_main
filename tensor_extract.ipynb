{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('dfdcpy37env': conda)",
   "display_name": "Python 3.7.6 64-bit ('dfdcpy37env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ed42f63bef822c8320ac08590f49c46eb48ce4dfa30453265a23ce003f333a3b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from importlib import reload\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "from albumentations import augmentations\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.pytorch\n",
    "\n",
    "df = pd.read_csv(\"tensor_sample.csv\")\n",
    "\n",
    "real = df[df[\"label\"] == 0].sample(n=3000)\n",
    "fakes = df[df[\"label\"] == 1].sample(n=3000)\n",
    "\n",
    "data = pd.concat([fakes, real])\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.merged_net import SRM_Classifer\n",
    "model = SRM_Classifer().to('cuda')\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=6000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dc77a680df341fa94b82646476176e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import image_ensemble\n",
    "reload(image_ensemble)\n",
    "from image_ensemble import ensemble\n",
    "\n",
    "root_dir = 'Image_Manipulation_Dataset/CASIA_2.0'\n",
    "out_dir = 'Image_Manipulation_Dataset/CASIA_2.0/1792_tensors'\n",
    "for row in tqdm_notebook(data):\n",
    "    image_patch, mask_patch, label, fold, ela = row\n",
    "\n",
    "    fname = image_patch.split('/')[-1][:-4]\n",
    "    if os.path.exists(os.path.join(out_dir, fname+\".pt\")):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(root_dir, image_patch)\n",
    "    ela_path = os.path.join(root_dir, ela)\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256,256), cv2.INTER_AREA)\n",
    "\n",
    "    ela_image = cv2.imread(ela_path, cv2.IMREAD_COLOR)\n",
    "    ela_image = cv2.cvtColor(ela_image, cv2.COLOR_BGR2RGB)\n",
    "    ela_image = cv2.resize(ela_image, (256,256), cv2.INTER_AREA)\n",
    "    \n",
    "    tensor = ensemble(model, image, ela_image).cpu().detach()\n",
    "    # print(type(tensor))\n",
    "    # print(tensor.shape)\n",
    "    torch.save(tensor, os.path.join(out_dir, fname+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "x = torch.load('Image_Manipulation_Dataset/CASIA_2.0/1792_tensors/Tp_D_CRN_M_N_pla10110_sec00046_10119.pt')\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('Image_Manipulation_Dataset/CASIA_2.0/1792_tensors')\n",
    "\n",
    "for x in files:\n",
    "    if x.startswith('Au'):\n",
    "        rows.append({\n",
    "            'fname':x,\n",
    "            'label':0\n",
    "        })\n",
    "    elif x.startswith('Tp'):\n",
    "        rows.append({\n",
    "            'fname':x,\n",
    "            'label':1\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                fname  label  fold\n",
       "0     Au_ani_00001.pt      0     0\n",
       "1     Au_ani_00003.pt      0     0\n",
       "2     Au_ani_00004.pt      0     0\n",
       "3     Au_ani_00005.pt      0     0\n",
       "4     Au_ani_00007.pt      0     0\n",
       "...               ...    ...   ...\n",
       "5995  Au_cha_30375.pt      0     9\n",
       "5996  Au_cha_30376.pt      0     9\n",
       "5997  Au_cha_30377.pt      0     9\n",
       "5998  Au_cha_30380.pt      0     9\n",
       "5999  Au_cha_30381.pt      0     9\n",
       "\n",
       "[6000 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Au_ani_00001.pt</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Au_ani_00003.pt</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Au_ani_00004.pt</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Au_ani_00005.pt</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Au_ani_00007.pt</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>Au_cha_30375.pt</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>Au_cha_30376.pt</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>Au_cha_30377.pt</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>Au_cha_30380.pt</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>Au_cha_30381.pt</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df2 = pd.DataFrame(rows)\n",
    "df2[\"fold\"] = -1  \n",
    "y = df2.label.values\n",
    "kf = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df2, y=y)):\n",
    "    df2.loc[v_, 'fold'] = f\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('1792_tensors.csv',index=False)"
   ]
  }
 ]
}