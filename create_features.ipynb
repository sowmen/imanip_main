{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from importlib import reload\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import albumentations\n",
    "from albumentations import augmentations\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('combo_all_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CASIA: real:749, fakes:511\nTEST: real:1353, fakes:1059\n"
     ]
    }
   ],
   "source": [
    "\"CMFD, NIST, COVERAGE, CASIA, IMD\"\n",
    "\n",
    "def get_individual_test_df(dataframe, val):\n",
    "    test_df = dataframe[dataframe['root_dir'].str.contains(val)]\n",
    "    test_df = test_df[test_df[\"fold\"].isin([1])]\n",
    "\n",
    "    print(\n",
    "        \"{}: real:{}, fakes:{}\".format(\n",
    "            val, len(test_df[test_df[\"label\"] == 0]), len(test_df[test_df[\"label\"] == 1])\n",
    "        )\n",
    "    )\n",
    "    return test_df.values\n",
    "\n",
    "def get_test_df(dataframe):\n",
    "    test_df = dataframe[dataframe[\"fold\"].isin([1])]\n",
    "\n",
    "    print(\n",
    "        \"TEST: real:{}, fakes:{}\".format(\n",
    "            len(test_df[test_df[\"label\"] == 0]), len(test_df[test_df[\"label\"] == 1])\n",
    "        )\n",
    "    )\n",
    "    return test_df.values\n",
    "    \n",
    "casia_test = get_individual_test_df(full_df, \"CASIA\")\n",
    "test_df = get_test_df(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"Image_Manipulation_Dataset\"\n",
    "def load_images(row):\n",
    "\n",
    "    image_patch, mask_patch, label, _, ela, root_dir = row\n",
    "\n",
    "    #------------- Load image, Ela, Mask -------------------------\n",
    "    image_path = os.path.join(root_folder, root_dir, image_patch)\n",
    "    ela_path = os.path.join(root_folder, root_dir, ela)\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    ela_image = cv2.imread(ela_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    ela_image = cv2.cvtColor(ela_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if not isinstance(mask_patch, str) and np.isnan(mask_patch):\n",
    "        mask_image = np.zeros((image.shape[0], image.shape[1])).astype('uint8')\n",
    "    else:\n",
    "        mask_path = os.path.join(root_folder, root_dir, mask_patch)\n",
    "        mask_image = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if('NIST' in root_dir):\n",
    "        mask_image = 255 - mask_image\n",
    "\n",
    "    image = augmentations.geometric.functional.resize(image, 256, 256, cv2.INTER_AREA)\n",
    "    mask_image = augmentations.geometric.functional.resize(mask_image, 256, 256, cv2.INTER_AREA)\n",
    "    ela_image = augmentations.geometric.functional.resize(ela_image, 256, 256, cv2.INTER_AREA)\n",
    "\n",
    "    return image, ela_image, mask_image, label\n",
    "\n",
    "\n",
    "\n",
    "def get_tensors(image, ela_image, mask_image):\n",
    "\n",
    "    #---------------- Reshape & Normalize -----------------------\n",
    "    image = augmentations.geometric.functional.resize(image, 256, 256, cv2.INTER_AREA)\n",
    "    mask_image = augmentations.geometric.functional.resize(mask_image, 256, 256, cv2.INTER_AREA)\n",
    "    ela_image = augmentations.geometric.functional.resize(ela_image, 256, 256, cv2.INTER_AREA)\n",
    "\n",
    "    normalize = {\n",
    "        \"mean\": [0.4535408213875562, 0.42862278450748387, 0.41780105499276865],\n",
    "        \"std\": [0.2672804038612597, 0.2550410416463668, 0.29475415579144293],\n",
    "    }\n",
    "\n",
    "    transforms_normalize = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean=normalize['mean'], std=normalize['std'], always_apply=True, p=1),\n",
    "            albumentations.pytorch.transforms.ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'ela':'image'}\n",
    "    )\n",
    "\n",
    "    data = transforms_normalize(image=image, mask=mask_image, ela=ela_image)\n",
    "    image_tensor = data[\"image\"].unsqueeze(0)\n",
    "    mask_tensor = (data[\"mask\"] / 255.0).unsqueeze(0).unsqueeze(0)\n",
    "    ela_tensor = data[\"ela\"].unsqueeze(0)\n",
    "    \n",
    "    return image_tensor, ela_tensor, mask_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_func(img, ela, mask, patch_size):\n",
    "    d = img.shape\n",
    "    patches = []\n",
    "    coords = []\n",
    "    for i in range(0, d[0], patch_size):\n",
    "        for j in range(0, d[1], patch_size):\n",
    "            x = i + patch_size\n",
    "            y = j + patch_size\n",
    "            if x > d[0] or y > d[1]:\n",
    "                break\n",
    "            temp_img = img[i: x, j: y]\n",
    "            temp_ela = ela[i: x, j: y]\n",
    "            temp_mask = mask[i: x, j: y]\n",
    "            patches.append((temp_img, temp_mask, temp_ela))\n",
    "            coords.append((i, j))\n",
    "    return patches, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from segmentation.merged_net import SRM_Classifer\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "model_256 = SRM_Classifer()\n",
    "model_256 = nn.DataParallel(model_256).to(device)\n",
    "model_256.load_state_dict(torch.load('best_weights/Changed classifier+COMBO_ALL_FULLSRM+ELA_[08|03_21|22|09].h5'))\n",
    "\n",
    "model_128 = SRM_Classifer()\n",
    "model_128 = nn.DataParallel(model_128).to(device)\n",
    "model_128.load_state_dict(torch.load('best_weights/COMBO_ALL_128ChangedClass_[09|03_21|11|14].h5'))\n",
    "\n",
    "model_64 = SRM_Classifer()\n",
    "model_64 = nn.DataParallel(model_64).to(device)\n",
    "model_64.load_state_dict(torch.load('best_weights/(Resume 22-35-18) COMBO_ALL_64ChangedClass_[11|03_18|46|12].h5'))\n",
    "\n",
    "# outputs = []\n",
    "# def hook(module, input, output):\n",
    "#     outputs.append(output)\n",
    "\n",
    "# handle_256 = model_256.module.classifier[4].register_forward_hook(hook)\n",
    "# handle_128 = model_128.module.classifier[4].register_forward_hook(hook)\n",
    "# handle_64 = model_64.module.classifier[4].register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_preds(row):\n",
    "    model_256.eval()\n",
    "    model_128.eval()\n",
    "    model_64.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_256, ela_image_256, mask_image_256, label = load_images(row)\n",
    "        features = []\n",
    "        predictions = []\n",
    "\n",
    "        #--------- 256x256 ----------        \n",
    "        image_tensor_256, ela_tensor_256, mask_tensor_256 = get_tensors(image_256, ela_image_256, mask_image_256)\n",
    "        # outputs.clear()\n",
    "        pred_256, inter_256, _ = model_256(image_tensor_256.to(device), ela_tensor_256.to(device))\n",
    "        features.append(inter_256.cpu().detach())\n",
    "        predictions.append(torch.sigmoid(pred_256.cpu().detach()))\n",
    "\n",
    "        #--------- 128x128 ----------\n",
    "        patches_128, _ = patch_func(image_256, ela_image_256, mask_image_256, 128)\n",
    "        for patch in patches_128:\n",
    "            image_128, mask_image_128, ela_image_128 = patch\n",
    "            image_tensor_128, ela_tensor_128, mask_tensor_128 = get_tensors(image_128, ela_image_128, mask_image_128)\n",
    "            \n",
    "            # outputs.clear()\n",
    "            pred_128, inter_128, _ = model_128(image_tensor_128.to(device), ela_tensor_128.to(device))\n",
    "            features.append(inter_128.cpu().detach())\n",
    "            predictions.append(torch.sigmoid(pred_128.cpu().detach()))\n",
    "        \n",
    "        #--------- 64x64 ----------\n",
    "        patches_64, _ = patch_func(image_256, ela_image_256, mask_image_256, 64)\n",
    "        for patch in patches_64:\n",
    "            image_64, mask_image_64, ela_image_64 = patch\n",
    "            image_tensor_64, ela_tensor_64, mask_tensor_64 = get_tensors(image_64, ela_image_64, mask_image_64)\n",
    "            \n",
    "            # outputs.clear()\n",
    "            pred_64, inter_64, _ = model_64(image_tensor_64.to(device), ela_tensor_64.to(device))\n",
    "            features.append(inter_64.cpu().detach())\n",
    "            predictions.append(torch.sigmoid(pred_64.cpu().detach()))\n",
    "\n",
    "    # torch.cuda.empty_cache()\n",
    "    return features, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_pool(feat: torch.tensor, operation: str):\n",
    "    \"\"\"\n",
    "    Fuses the image's patches feature representation\n",
    "    :param feat: The network object\n",
    "    :param operation: Either max or mean for the pooling operation\n",
    "    :returns: The final 256-D feature representation of the entire image\n",
    "    \"\"\"\n",
    "    if operation == \"max\":\n",
    "        return feat.max(axis=0)\n",
    "    elif operation == \"mean\":\n",
    "        return feat.mean(axis=0)\n",
    "    else:\n",
    "        raise Exception(\"The operation can be either mean or max\")\n",
    "\n",
    "def print_preds(predictions):\n",
    "    print(predictions[0].item())\n",
    "    print(\"------\")\n",
    "    print(predictions[1].item(), predictions[2].item())\n",
    "    print(predictions[3].item(), predictions[4].item())\n",
    "    print(\"------\")\n",
    "    print(predictions[5].item(), predictions[6].item(), predictions[7].item(), predictions[8].item())\n",
    "    print(predictions[9].item(), predictions[10].item(), predictions[11].item(), predictions[12].item())\n",
    "    print(predictions[13].item(), predictions[14].item(), predictions[15].item(), predictions[16].item())\n",
    "    print(predictions[17].item(), predictions[18].item(), predictions[19].item(), predictions[20].item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_FULL = []\n",
    "test_preds_MEAN = []\n",
    "test_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 23508/23508 [4:09:52<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(full_df.values):\n",
    "\n",
    "    features, predictions = get_feat_preds(row)\n",
    "    \n",
    "    features = torch.vstack(features)\n",
    "    # condensed_feat = feat_pool(features, \"mean\")\n",
    "    all_features.append({\n",
    "        \"image\" : row[0],\n",
    "        \"label\" : row[2],\n",
    "        \"mask\" : row[1],\n",
    "        \"fold\" : row[3],\n",
    "        \"root_dir\" : row[-1],\n",
    "        \"feature\" : features\n",
    "    })\n",
    "    # print_preds(predictions)    \n",
    "    # print(torch.cat(predictions).mean())\n",
    "    # print(torch.cat(predictions[1:5]).mean())\n",
    "    # print(torch.cat(predictions[5:]).mean())\n",
    "\n",
    "    all_predictions.append({\n",
    "        \"image\" : row[0],\n",
    "        \"label\" : row[2],\n",
    "        \"mask\" : row[1],\n",
    "        \"fold\" : row[3],\n",
    "        \"root_dir\" : row[-1],\n",
    "        \"predictions\" : [x.item() for x in predictions]\n",
    "    })\n",
    "\n",
    "    if(row[3] == 1):\n",
    "        test_targets.append(row[2])\n",
    "        test_preds_FULL.append(predictions[0].item())\n",
    "        test_preds_MEAN.append(torch.cat(predictions).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 23508/23508 [00:17<00:00, 1347.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(all_features):\n",
    "    name = x[\"root_dir\"].split('/')[0] +\"_\"+ x[\"image\"].split('/')[-1]\n",
    "    tensor = x[\"feature\"]\n",
    "    torch.save(tensor, os.path.join('256_features', name[:-3]+\"pt\"))\n",
    "\n",
    "    saved_features.append({\n",
    "        \"image\" : x[\"image\"],\n",
    "        \"label\" : x[\"label\"],\n",
    "        \"mask\" : x[\"mask\"],\n",
    "        \"fold\" : x[\"fold\"],\n",
    "        \"root_dir\" : x[\"root_dir\"],\n",
    "        \"feature\" : os.path.join('256_features', name[:-3]+\"pt\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('all_predictions.json', 'w') as fout:\n",
    "    json.dump(all_predictions , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(saved_features)\n",
    "features_df.to_csv('all_features.csv', index=False)"
   ]
  }
 ]
}