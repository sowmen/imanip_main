{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5454afb7ffb1799ae1d6fe9b1ee82f9b07495275ac0b3d18cfab38f9bedde77"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from importlib import reload\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import albumentations\n",
    "from albumentations import augmentations\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('combo_all_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CASIA: real:749, fakes:511\n"
     ]
    }
   ],
   "source": [
    "\"CMFD, NIST, COVERAGE, CASIA, IMD\"\n",
    "\n",
    "def get_test_df(dataframe, val):\n",
    "    test_df = dataframe[dataframe['root_dir'].str.contains(val)]\n",
    "    test_df = test_df[test_df[\"fold\"].isin([1])]\n",
    "\n",
    "    print(\n",
    "        \"{}: real:{}, fakes:{}\".format(\n",
    "            val, len(test_df[test_df[\"label\"] == 0]), len(test_df[test_df[\"label\"] == 1])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return test_df.values\n",
    "\n",
    "casia_test = get_test_df(full_df, \"CASIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"Image_Manipulation_Dataset\"\n",
    "def load_images(row):\n",
    "\n",
    "    image_patch, mask_patch, label, _, ela, root_dir = row\n",
    "\n",
    "    #------------- Load image, Ela, Mask -------------------------\n",
    "    image_path = os.path.join(root_folder, root_dir, image_patch)\n",
    "    ela_path = os.path.join(root_folder, root_dir, ela)\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    ela_image = cv2.imread(ela_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    ela_image = cv2.cvtColor(ela_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if not isinstance(mask_patch, str) and np.isnan(mask_patch):\n",
    "        mask_image = np.zeros((image.shape[0], image.shape[1])).astype('uint8')\n",
    "    else:\n",
    "        mask_path = os.path.join(self.root_folder, root_dir, mask_patch)\n",
    "        mask_image = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if('NIST' in root_dir):\n",
    "        mask_image = 255 - mask_image\n",
    "\n",
    "    image = augmentations.geometric.functional.resize(image, 256, 256, cv2.INTER_AREA)\n",
    "    mask_image = augmentations.geometric.functional.resize(mask_image, 256, 256, cv2.INTER_AREA)\n",
    "    ela_image = augmentations.geometric.functional.resize(ela_image, 256, 256, cv2.INTER_AREA)\n",
    "\n",
    "    return image, ela_image, mask_image, label\n",
    "\n",
    "\n",
    "\n",
    "def get_tensors(image, ela_image, mask_image):\n",
    "\n",
    "    #---------------- Reshape & Normalize -----------------------\n",
    "    normalize = {\n",
    "        \"mean\": [0.4535408213875562, 0.42862278450748387, 0.41780105499276865],\n",
    "        \"std\": [0.2672804038612597, 0.2550410416463668, 0.29475415579144293],\n",
    "    }\n",
    "\n",
    "    transforms_normalize = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean=normalize['mean'], std=normalize['std'], always_apply=True, p=1),\n",
    "            albumentations.pytorch.transforms.ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'ela':'image'}\n",
    "    )\n",
    "\n",
    "    data = transforms_normalize(image=image, mask=mask_image, ela=ela_image)\n",
    "    image = data[\"image\"].unsqueeze(0)\n",
    "    mask_image = (data[\"mask\"] / 255.0).unsqueeze(0).unsqueeze(0)\n",
    "    ela_image = data[\"ela\"].unsqueeze(0)\n",
    "    \n",
    "    return image, ela_image, mask_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_func(img, ela, mask, patch_size):\n",
    "    d = img.shape\n",
    "    patches = []\n",
    "    coords = []\n",
    "    for i in range(0, d[0], patch_size):\n",
    "        for j in range(0, d[1], patch_size):\n",
    "            x = i + patch_size\n",
    "            y = j + patch_size\n",
    "            if x > d[0] or y > d[1]:\n",
    "                break\n",
    "            temp_img = img[i: x, j: y]\n",
    "            temp_ela = ela[i: x, j: y]\n",
    "            temp_mask = mask[i: x, j: y]\n",
    "            patches.append((temp_img, temp_mask, temp_ela))\n",
    "            coords.append((i, j))\n",
    "    return patches, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'SRM_Classifier' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a705509c332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSRM_Classifer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRM_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SRM_Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from segmentation.merged_net import SRM_Classifer\n",
    "\n",
    "model = SRM_Classifier()\n",
    "\n",
    "outputs= []\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "model.module.classifier[4].register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Au/Au_ani_30033.jpg\n"
     ]
    }
   ],
   "source": [
    "for row in casia_test[:1]:\n",
    "    print(row[0])\n",
    "\n",
    "    image_256, ela_image_256, mask_image_256, label = load_images(row)\n",
    "    patches_128, _ = patch_func(image_256, ela_image_256, mask_image_256, 128)\n",
    "    "
   ]
  }
 ]
}