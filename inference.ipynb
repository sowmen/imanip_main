{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import albumentations\n",
    "from albumentations import augmentations\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"Image_Manipulation_Dataset\"\n",
    "\n",
    "def load_images(row):\n",
    "\n",
    "    image_patch, mask_patch, label, _, ela, root_dir = row\n",
    "\n",
    "    #------------- Load image, Ela, Mask -------------------------\n",
    "    image_path = os.path.join(root_folder, root_dir, image_patch)\n",
    "    ela_path = os.path.join(root_folder, root_dir, ela)\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    ela_image = cv2.imread(ela_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    ela_image = cv2.cvtColor(ela_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if not isinstance(mask_patch, str) and np.isnan(mask_patch):\n",
    "        mask_image = np.zeros((image.shape[0], image.shape[1])).astype('uint8')\n",
    "    else:\n",
    "        mask_path = os.path.join(root_folder, root_dir, mask_patch)\n",
    "        mask_image = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # if('NIST' in root_dir):\n",
    "    #     mask_image = 255 - mask_image\n",
    "\n",
    "    image = augmentations.geometric.functional.resize(image, 256, 256, cv2.INTER_AREA)\n",
    "    mask_image = augmentations.geometric.functional.resize(mask_image, 256, 256, cv2.INTER_AREA)\n",
    "    ela_image = augmentations.geometric.functional.resize(ela_image, 256, 256, cv2.INTER_AREA)\n",
    "\n",
    "    return image, ela_image, mask_image, label\n",
    "\n",
    "\n",
    "\n",
    "def get_tensors(image, ela_image, mask_image):\n",
    "\n",
    "    #---------------- Normalize -----------------------\n",
    "\n",
    "    normalize = {\n",
    "        \"mean\": [0.4535408213875562, 0.42862278450748387, 0.41780105499276865],\n",
    "        \"std\": [0.2672804038612597, 0.2550410416463668, 0.29475415579144293],\n",
    "    }\n",
    "\n",
    "    transforms_normalize = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean=normalize['mean'], std=normalize['std'], always_apply=True, p=1),\n",
    "            albumentations.pytorch.transforms.ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'ela':'image'}\n",
    "    )\n",
    "\n",
    "    data = transforms_normalize(image=image, mask=mask_image, ela=ela_image)\n",
    "    image_tensor = data[\"image\"].unsqueeze(0)\n",
    "    mask_tensor = (data[\"mask\"] / 255.0).unsqueeze(0).unsqueeze(0)\n",
    "    ela_tensor = data[\"ela\"].unsqueeze(0)\n",
    "    \n",
    "    return image_tensor, ela_tensor, mask_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.merged_netv2 import Mani_FeatX\n",
    "from segmentation.unetpp_v2 import MyUnetPP\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "encoder = Mani_FeatX(encoder_attention=None)\n",
    "model = MyUnetPP(encoder)\n",
    "\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('weights/(ALL_TRAIN_GTX)MyUnetPP-v2-Attn(Enc-None, Dec-GCA+SCSE)_[30|06_16|04|45].h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_preds(row):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image, ela_image, mask_image, label = load_images(row)\n",
    "        image_tensor, ela_tensor, mask_tensor = get_tensors(image, ela_image, mask_image)\n",
    "        \n",
    "        mask_pred, label_pred = model(image_tensor.to(device), ela_tensor.to(device))\n",
    "\n",
    "        mask_prediction = torch.sigmoid(mask_pred.cpu().detach())\n",
    "        mask_gt = mask_tensor\n",
    "        label_preds = torch.sigmoid(label_pred.cpu().detach())\n",
    "        label_gt = label\n",
    "        \n",
    "    return mask_prediction, mask_gt, label_preds, label_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real:749, fakes:511\n",
      "real:151, fakes:144\n",
      "real:10, fakes:10\n",
      "real:0, fakes:80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\"CMFD, NIST, COVERAGE, CASIA, IMD\"\n",
    "\n",
    "def get_test_df(path, only_fake=False):\n",
    "    dataframe = pd.read_csv(path)\n",
    "    test_df = dataframe[dataframe[\"fold\"].isin([1])]\n",
    "    if only_fake:\n",
    "        test_df = test_df[test_df[\"label\"] == 1]\n",
    "\n",
    "    print(\n",
    "        \"real:{}, fakes:{}\".format(\n",
    "            len(test_df[test_df[\"label\"] == 0]), len(test_df[test_df[\"label\"] == 1])\n",
    "        )\n",
    "    )\n",
    "    return test_df.values\n",
    "\n",
    "\n",
    "casia_test = get_test_df('dataset_csv/casia_FULL.csv')\n",
    "imd_test = get_test_df('dataset_csv/imd_FULL.csv')\n",
    "coverage_test = get_test_df('dataset_csv/coverage_FULL.csv')\n",
    "nist_test = get_test_df('dataset_csv/nist16v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casia_full = pd.read_csv('dataset_csv/casia_FULL.csv')\n",
    "casia_full = casia_full[casia_full[\"fold\"].isin([1])]\n",
    "casia_real = casia_full[casia_full['label'] == 0].sample(n=200)\n",
    "casia_fake = casia_full[casia_full['label'] == 1].sample(n=100)\n",
    "\n",
    "imd_full = pd.read_csv('dataset_csv/imd_FULL.csv')\n",
    "imd_full = imd_full[imd_full[\"fold\"].isin([1])]\n",
    "imd_real = imd_full[imd_full['label'] == 0]\n",
    "imd_fake = imd_full[imd_full['label'] == 1].sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred_label = []\n",
    "pred_mask = []\n",
    "gt_mask = []\n",
    "\n",
    "for row in tqdm(casia_test):\n",
    "    mask_predictions, mask_gt, label_preds, label_gt = get_feat_preds(row)\n",
    "    \n",
    "    pred_label.append(label_preds.squeeze())\n",
    "    label.append(label_gt)\n",
    "    pred_mask.append(mask_predictions.squeeze())\n",
    "    gt_mask.append(mask_gt.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(np.array(label) >= 0.5, np.array(pred_label) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc, cnt = 0, 0\n",
    "for gt, pr in tqdm(zip(gt_mask, pred_mask)):          \n",
    "    auc += roc_auc_score(gt.ravel() >= 0.5, pr.ravel())\n",
    "    cnt += 1\n",
    "auc / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "thrs = [0.0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\n",
    "\n",
    "sample = []\n",
    "auc, cnt = 0, 0\n",
    "for gt, pr in tqdm(zip(gt_mask, pred_mask)):\n",
    "    best, bt = -1, 0\n",
    "    for thr in thrs:\n",
    "        tmp = roc_auc_score(gt.numpy().ravel() >= 0.5, pr.numpy().ravel() >= thr)          \n",
    "        if tmp > best: \n",
    "            best = tmp\n",
    "            bt = thr\n",
    "    auc += best\n",
    "    cnt += 1\n",
    "    sample.append((pr, gt, bt))\n",
    "auc / cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_ela\n",
    "\n",
    "image_path = ''\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "ela_image = get_ela(image, 25)\n",
    "\n",
    "image = augmentations.geometric.functional.resize(image, 256, 256, cv2.INTER_AREA)\n",
    "ela_image = augmentations.geometric.functional.resize(ela_image, 256, 256, cv2.INTER_AREA)\n",
    "mask_image = np.zeros((image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "image_tensor, ela_tensor, mask_tensor = get_tensors(image, ela_image, mask_image)\n",
    "        \n",
    "mask_pred, label_pred = model(image_tensor.to(device), ela_tensor.to(device))\n",
    "\n",
    "mask_prediction = torch.sigmoid(mask_pred.cpu().detach())\n",
    "label_pred = torch.sigmoid(label_pred.cpu().detach())\n",
    "\n",
    "print(label_pred)\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask_prediction, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c37635652f2202170c5941e98822fbd066681d6607567fc23bb9a6fdd81ef1b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
